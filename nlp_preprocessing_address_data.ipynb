{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f9776b7cf7ae4923af1b875badfb7150": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f79cdd7aa6514c218d166c0f17c53ad0"
            ],
            "layout": "IPY_MODEL_656b369cf05047149456fb7495d52d3e"
          }
        },
        "4f0c292dd4f64f468463f7442e24d5e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_460fbcc5657744d899a843385da96b93",
            "placeholder": "​",
            "style": "IPY_MODEL_24070b9d12df443f803cf6d1ebe1f5aa",
            "value": "<center> <img\nsrc=https://www.kaggle.com/static/images/site-logo.png\nalt='Kaggle'> <br> Create an API token from <a\nhref=\"https://www.kaggle.com/settings/account\" target=\"_blank\">your Kaggle\nsettings page</a> and paste it below along with your Kaggle username. <br> </center>"
          }
        },
        "436ab4432f8e402cbc6d309be9fa8af7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "Username:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_7ca6dd43b9594705bc5e8b49e8da4475",
            "placeholder": "​",
            "style": "IPY_MODEL_f1d51efaf59246b7bb76860dd57c10bf",
            "value": "edudum"
          }
        },
        "5c0c3b6159b74f1396df191672af26ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_c191ae4c8fdb4522a3a5c2518e7955e2",
            "placeholder": "​",
            "style": "IPY_MODEL_ebe3ccc8a5c1495397076a7225493142",
            "value": ""
          }
        },
        "4713b46c8b1a41beb6e474a413de663c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_8b860c6410574dc7ac91f8388b19ad2a",
            "style": "IPY_MODEL_6d3dcf3ed1854daf9f64149044955c0f",
            "tooltip": ""
          }
        },
        "5d3d9e7c5833426db673464d61208831": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2e4480865b2423f8df5866566190a30",
            "placeholder": "​",
            "style": "IPY_MODEL_2f71cd2f5b5f4a48a3e18d3b50613715",
            "value": "\n<b>Thank You</b></center>"
          }
        },
        "656b369cf05047149456fb7495d52d3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "460fbcc5657744d899a843385da96b93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24070b9d12df443f803cf6d1ebe1f5aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ca6dd43b9594705bc5e8b49e8da4475": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1d51efaf59246b7bb76860dd57c10bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c191ae4c8fdb4522a3a5c2518e7955e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebe3ccc8a5c1495397076a7225493142": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b860c6410574dc7ac91f8388b19ad2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d3dcf3ed1854daf9f64149044955c0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "f2e4480865b2423f8df5866566190a30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f71cd2f5b5f4a48a3e18d3b50613715": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "69a02a6888764aa1b3c442480d735176": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd6108dc7da5481683e29bb7767279a0",
            "placeholder": "​",
            "style": "IPY_MODEL_286c8fec38a740e1b082f76a1dcb7265",
            "value": "Connecting..."
          }
        },
        "bd6108dc7da5481683e29bb7767279a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "286c8fec38a740e1b082f76a1dcb7265": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f79cdd7aa6514c218d166c0f17c53ad0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45f99d112b57426897625942d24e5a81",
            "placeholder": "​",
            "style": "IPY_MODEL_dbb535386ae54fa09028283bc5003ccc",
            "value": "Kaggle credentials successfully validated."
          }
        },
        "45f99d112b57426897625942d24e5a81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbb535386ae54fa09028283bc5003ccc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "Bn4zQYM3pi70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "f9776b7cf7ae4923af1b875badfb7150",
            "4f0c292dd4f64f468463f7442e24d5e9",
            "436ab4432f8e402cbc6d309be9fa8af7",
            "5c0c3b6159b74f1396df191672af26ad",
            "4713b46c8b1a41beb6e474a413de663c",
            "5d3d9e7c5833426db673464d61208831",
            "656b369cf05047149456fb7495d52d3e",
            "460fbcc5657744d899a843385da96b93",
            "24070b9d12df443f803cf6d1ebe1f5aa",
            "7ca6dd43b9594705bc5e8b49e8da4475",
            "f1d51efaf59246b7bb76860dd57c10bf",
            "c191ae4c8fdb4522a3a5c2518e7955e2",
            "ebe3ccc8a5c1495397076a7225493142",
            "8b860c6410574dc7ac91f8388b19ad2a",
            "6d3dcf3ed1854daf9f64149044955c0f",
            "f2e4480865b2423f8df5866566190a30",
            "2f71cd2f5b5f4a48a3e18d3b50613715",
            "69a02a6888764aa1b3c442480d735176",
            "bd6108dc7da5481683e29bb7767279a0",
            "286c8fec38a740e1b082f76a1dcb7265",
            "f79cdd7aa6514c218d166c0f17c53ad0",
            "45f99d112b57426897625942d24e5a81",
            "dbb535386ae54fa09028283bc5003ccc"
          ]
        },
        "outputId": "32d9d6bd-5069-46d0-e76b-aec04bf988fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://www.kaggle.com/static/images/site-logo.png\\nalt=\\'Kaggle…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f9776b7cf7ae4923af1b875badfb7150"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kaggle credentials set.\n",
            "Kaggle credentials successfully validated.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "data_path = kagglehub.competition_download('***')\n",
        "edudum_mahalle_listesi_path = kagglehub.dataset_download('edudum/mahalle-listesi') #NVİ mahalle listesi\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "9FpOyzFftxGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
        "\n"
      ],
      "metadata": {
        "id": "GeIWj7rztzBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -q datasets\n",
        "! pip install unidecode -q\n",
        "! pip install rapidfuzz -q\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from unidecode import unidecode\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "import joblib\n",
        "from pathlib import Path\n",
        "import matplotlib as plt\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBJAiTbet2NW",
        "outputId": "a693a3c9-0089-433d-adff-f16726f9a499"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.8/235.8 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Build file paths\n",
        "train_path = os.path.join(data_path, \"train.csv\")\n",
        "test_path  = os.path.join(data_path, \"test.csv\")\n",
        "\n",
        "# Read CSVs\n",
        "train_df = pd.read_csv(train_path)\n",
        "test_df  = pd.read_csv(test_path)\n",
        "\n",
        "print(\"Train shape:\", train_df.shape)\n",
        "print(\"Test shape:\", test_df.shape)\n",
        "print(train_df.head())\n",
        "\n"
      ],
      "metadata": {
        "id": "enI19UKft2-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import re\n",
        "from unidecode import unidecode\n",
        "\n",
        "def normalize_address(text):\n",
        "    # Lowercase and apply unidecode for Turkish characters\n",
        "    text = unidecode(text.lower())\n",
        "\n",
        "    # Expand common abbreviations\n",
        "    text = re.sub(r'\\b(mahalle|mah|mhl|mh)\\.?\\b', 'mahallesi', text)\n",
        "    text = re.sub(r'\\b(cadde|cadd|cad|cd)\\.?\\b', 'caddesi', text)\n",
        "    text = re.sub(r'\\b(bulv|blv)\\.?\\b', 'bulvari', text)\n",
        "    text = re.sub(r'\\b(sok|skk|sk)\\.?\\b', 'sokak', text)\n",
        "    text = re.sub(r'\\b(blk|bl)\\.?\\b', 'blok', text)\n",
        "    text = re.sub(r'\\b(no|num)\\.?\\b', 'numara', text)\n",
        "\n",
        "    # Fix wrong naming\n",
        "    text = text.replace('sokagi', 'sokak')\n",
        "\n",
        "    # Remove TR/Turkiye\n",
        "    text = text.replace('TR', '')\n",
        "    text = text.replace('Turkiye', '')\n",
        "    text = text.replace(\"tr\", \"\")\n",
        "\n",
        "\n",
        "    # Replace new lines\n",
        "    text = text.replace('\\n', ' ')\n",
        "\n",
        "    # Replace slashes '/'\n",
        "    text = re.sub(r'(?<=[A-Za-z])/(?=[A-Za-z])', ' ', text)\n",
        "\n",
        "    # Remove all punctuation if not between two digits\n",
        "    text = re.sub(r'(?<!\\d)[^\\w\\s]|[^\\w\\s](?!\\d)', '', text)\n",
        "\n",
        "    # Remove excess whitespace\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    return text\n",
        "\n",
        "# # Read CSV into list of dictionaries\n",
        "# with open('/kaggle/input/***/train.csv', newline='', encoding='utf-8') as csvfile:\n",
        "#     reader = csv.DictReader(csvfile)\n",
        "#     data = [row for row in reader]\n",
        "\n",
        "# # Example\n",
        "# for i in range (10):\n",
        "#     address = data[i][\"address\"]\n",
        "#     print(normalize_address(address))\n"
      ],
      "metadata": {
        "id": "WltKmZ_8uCRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mahalle_excel_path = os.path.join(edudum_mahalle_listesi_path, \"Mahalle_Listesi.xls\")\n",
        "gazetteer_df = pd.read_excel(mahalle_excel_path)\n",
        "\n",
        "gazetteer_df.columns = ['sira', 'mahalle_adi', 'baglilik_bilgisi']"
      ],
      "metadata": {
        "id": "HFgnaqftvvBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip -q install tqdm tenacity\n",
        "# import os, json, time, math, pandas as pd\n",
        "# import requests\n",
        "# from tqdm.auto import tqdm\n",
        "# from tenacity import retry, wait_exponential, stop_after_attempt, retry_if_exception_type\n"
      ],
      "metadata": {
        "id": "SC2h7mtIAJ2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## demo for understanding performance of GPT's on this task.\n",
        "# os.environ[\"OPENROUTER_API_KEY\"] = os.environ.get(\"OPENROUTER_API_KEY\", \"API_KEY\")\n",
        "\n",
        "# OPENROUTER_URL = \"https://openrouter.ai/api/v1/chat/completions\"\n",
        "# MODEL = \"deepseek/deepseek-chat-v3-0324:free\"  # ücretsiz rota\n",
        "\n",
        "# HEADERS = {\n",
        "#     \"Authorization\": f\"Bearer {os.environ['OPENROUTER_API_KEY']}\",\n",
        "#     \"Content-Type\": \"application/json\",\n",
        "# }\n",
        "\n",
        "# SYSTEM_PROMPT = (\n",
        "#     \"Görevin: Türkçe serbest metin adreslerini normalize etmek.\\n\"\n",
        "#     \"- Yazım hatalarını düzelt (Türkçe karakterleri koru).\\n\"\n",
        "#     \"- Kısaltmaları genişlet: 'mah'->'Mahallesi', 'cad'->'Caddesi', 'sk'/'sok'->'Sokak', \"\n",
        "#     \"'blv'->'Bulvarı', 'no'/'num'->'No'.\\n\"\n",
        "#     \"- Yapışık yazılanları ayır: 'cadde5'->'Cadde 5', 'no10'->'No 10', 'kat3'->'Kat 3'.\\n\"\n",
        "#     \"- Anlamı değiştirme, veri kaybetme: tüm sayı, blok/daire/kat/site vs. kalsın.\\n\"\n",
        "#     \"- İl/ilçe/mahalle adlarını büyük harf uyumlu yaz (sadece özel adların ilk harfi büyük).\\n\"\n",
        "#     \"- Sadece normalize edilmiş adresi tek satırda döndür; başka açıklama ekleme.\"\n",
        "# )\n",
        "\n",
        "# def build_user_prompt(addr: str) -> str:\n",
        "#     return f\"Adres: {addr}\"\n",
        "\n",
        "# class TransientAPIError(Exception):\n",
        "#     pass\n",
        "\n",
        "# @retry(\n",
        "#     wait=wait_exponential(multiplier=1, min=1, max=60),\n",
        "#     stop=stop_after_attempt(6),\n",
        "#     retry=retry_if_exception_type(TransientAPIError),\n",
        "# )\n",
        "# def normalize_address_llm(addr: str) -> str:\n",
        "#     payload = {\n",
        "#         \"model\": MODEL,\n",
        "#         \"messages\": [\n",
        "#             {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "#             {\"role\": \"user\", \"content\": build_user_prompt(addr)}\n",
        "#         ],\n",
        "#         \"temperature\": 0,\n",
        "#         \"max_tokens\": 256,\n",
        "#     }\n",
        "#     r = requests.post(OPENROUTER_URL, headers=HEADERS, json=payload, timeout=60)\n",
        "#     if r.status_code in (429, 500, 502, 503, 504):\n",
        "#         # geçici hata → yeniden dene\n",
        "#         raise TransientAPIError(f\"{r.status_code} {r.text[:200]}\")\n",
        "#     r.raise_for_status()\n",
        "#     data = r.json()\n",
        "#     out = data[\"choices\"][0][\"message\"][\"content\"].strip()\n",
        "#     # Güvenlik: tek satır ve kontrol\n",
        "#     return \" \".join(out.split())\n"
      ],
      "metadata": {
        "id": "4C3u8lmGCyIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tests = [\n",
        "#     \"cumhurıyet mah.hukumet cad.olcay koç ishani no5 kat2 daire5 fethiye/mugla\",\n",
        "#     \"dumlupınar mah 1234 sk no14/5 d blok kat1 d4 izmir karşıyaka\",\n",
        "#     \"bahcelievler mh 8.cad 24.sk no:13a site4 blokb daire:25 Ankara/çankaya\"\n",
        "# ]\n",
        "# for t in tests:\n",
        "#     print(\"IN :\", t)\n",
        "#     print(\"OUT:\", normalize_address_llm(t))\n",
        "#     print(\"---\")\n"
      ],
      "metadata": {
        "id": "4j2aolWsEo-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# downloading zemberek nlp model for normalization and etc.\n",
        "# !wget -O zemberek-full.jar \"https://drive.google.com/uc?export=download&id=1RRuFK43JqcHcthB3fV2IEpPftWoeoHAu\"\n",
        "!gdown --id 1RRuFK43JqcHcthB3fV2IEpPftWoeoHAu -O zemberek-full.jar\n",
        "!pip install jpype1\n",
        "!pip install zemberek-python\n",
        "import gdown\n",
        "\n",
        "# Download normalization directory\n",
        "gdown.download_folder('https://drive.google.com/drive/folders/1jNT6BJoEbiLuVbQwBYdVNoibEdzDd2WC?usp=drive_link', quiet=False)\n",
        "\n",
        "# Download lm.2gram.slm file\n",
        "gdown.download('https://drive.google.com/uc?export=download&id=1JZG0I8jUS511lFVg0M-QAA4QRqydlCiX', 'lm.2gram.slm', quiet=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8LUcno2GJe2",
        "outputId": "f943fb53-4f2d-4aba-f4cd-30823e11cf67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1RRuFK43JqcHcthB3fV2IEpPftWoeoHAu\n",
            "From (redirected): https://drive.google.com/uc?id=1RRuFK43JqcHcthB3fV2IEpPftWoeoHAu&confirm=t&uuid=88d5a625-ce66-4122-a81d-83f4173edc22\n",
            "To: /content/zemberek-full.jar\n",
            "100% 31.6M/31.6M [00:00<00:00, 57.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Citation:** <br>\n",
        "***zemberek-nlp*** <br>\n",
        "https://github.com/ahmetaa/zemberek-nlp/tree/master"
      ],
      "metadata": {
        "id": "axq975jOVJC7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## demo to understand how zemberek works\n",
        "# %%writefile NormalizeAddress.java\n",
        "# import zemberek.normalization.TurkishSentenceNormalizer;\n",
        "# import zemberek.morphology.TurkishMorphology;\n",
        "# import java.nio.file.Path;\n",
        "\n",
        "# public class NormalizeAddress {\n",
        "#     public static void main(String[] args) throws Exception {\n",
        "#         TurkishMorphology morphology = TurkishMorphology.createWithDefaults();\n",
        "\n",
        "#         Path root = Path.of(\"zemberek-data\"); // dil modeli dosyaları\n",
        "\n",
        "#         TurkishSentenceNormalizer normalizer =\n",
        "#             new TurkishSentenceNormalizer(\n",
        "#                 morphology,\n",
        "#                 root.resolve(\"normalization\"),\n",
        "#                 root.resolve(\"lm\")\n",
        "#             );\n",
        "\n",
        "#         String input = \"ankra cadd5 no12 dky mah.\";\n",
        "#         String normalized = normalizer.normalize(input);\n",
        "#         System.out.println(\"Input   : \" + input);\n",
        "#         System.out.println(\"Output  : \" + normalized);\n",
        "#     }\n",
        "# }\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpkIxvk6GPCw",
        "outputId": "17906b39-8100-4844-f339-aec7f2619e34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting NormalizeAddress.java\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !javac -cp zemberek-full.jar NormalizeAddress.java"
      ],
      "metadata": {
        "id": "Cfg47Vm-GYZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !java -cp .:zemberek-full.jar NormalizeAddress\n"
      ],
      "metadata": {
        "id": "avQHY9qzH-Ff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import jpype\n",
        "# from jpype import JClass\n",
        "\n",
        "# # Start the JVM\n",
        "# jpype.startJVM(jpype.getDefaultJVMPath(), '-ea', '-Djava.class.path=path_to_zemberek_full.jar')\n",
        "\n",
        "# # Load necessary classes\n",
        "# TurkishSentenceNormalizer = JClass('zemberek.normalization.TurkishSentenceNormalizer')\n",
        "# lm_path = 'lm.2gram.slm'\n",
        "# normalizer = TurkishSentenceNormalizer(lm_path)\n",
        "\n",
        "# # Example sentence\n",
        "# sentence = 'Bugün hava çok güzel. Hadi dışarı çıkalım.'\n",
        "\n",
        "# # Normalize the sentence\n",
        "# normalized_sentence = normalizer.normalize(sentence)\n",
        "# print(normalized_sentence)\n"
      ],
      "metadata": {
        "id": "Y8s812vxMPaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###\n",
        "> ### IMPLEMENTATION STARTS FROM HERE ON!\n",
        "###"
      ],
      "metadata": {
        "id": "x7igbOaHXMSP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "! pip install -q datasets\n",
        "! pip install unidecode -q\n",
        "! pip install rapidfuzz -q\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from unidecode import unidecode\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "import joblib\n",
        "from pathlib import Path\n",
        "import matplotlib as plt\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "data_path = kagglehub.competition_download('***')\n",
        "edudum_mahalle_listesi_path = kagglehub.dataset_download('edudum/mahalle-listesi')\n",
        "\n",
        "print('Data source import complete.')\n",
        "\n",
        "# !wget -O zemberek-full.jar \"https://drive.google.com/uc?export=download&id=1RRuFK43JqcHcthB3fV2IEpPftWoeoHAu\"\n",
        "!gdown --id 1RRuFK43JqcHcthB3fV2IEpPftWoeoHAu -O zemberek-full.jar\n",
        "!pip install jpype1\n",
        "!pip install zemberek-python\n",
        "import gdown\n",
        "\n",
        "# Download normalization directory\n",
        "gdown.download_folder('https://drive.google.com/drive/folders/1jNT6BJoEbiLuVbQwBYdVNoibEdzDd2WC?usp=drive_link', quiet=False)\n",
        "\n",
        "# Download lm.2gram.slm file\n",
        "gdown.download('https://drive.google.com/uc?export=download&id=1JZG0I8jUS511lFVg0M-QAA4QRqydlCiX', 'lm.2gram.slm', quiet=False)"
      ],
      "metadata": {
        "id": "S9V2JRsC15OS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------\n",
        "# PRE-NORMALIZATION (before Zemberek)\n",
        "# -----------------------------------------\n",
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "from unidecode import unidecode\n",
        "\n",
        "# -------- Manual pre-normalization --------\n",
        "def pre_normalize_manual(text: str) -> str:\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "    text = unidecode(text.lower())\n",
        "    # Common abbreviations\n",
        "    text = re.sub(r'\\b(mahalle|mah|mhl|mh)\\b', 'mahallesi', text)\n",
        "    text = re.sub(r'\\b(cadde|cadd|cad|cd)\\b', 'caddesi', text)\n",
        "    text = re.sub(r'\\b(sokak|sok|skk|sk)\\b', 'sokagi', text)\n",
        "    text = re.sub(r'\\b(bulvari|bulv|blv)\\b', 'bulvari', text)\n",
        "    text = re.sub(r'\\b(apartmani|apt|ap)\\b', 'apartmani', text)\n",
        "    text = re.sub(r'\\b(numara|no|nu)\\b', 'numara', text)\n",
        "    text = re.sub(r'\\b(daire|dai|d)\\b', 'daire', text)\n",
        "    text = re.sub(r'\\b(kat|k)\\b', 'kat', text)\n",
        "    text = re.sub(r'\\b(blok|blk|bl)\\b', 'blok', text)\n",
        "    text = re.sub(r'\\b(tr|turkiye|turkey)\\b', '', text)\n",
        "\n",
        "    # Replace slashes, punctuation etc.\n",
        "    text = re.sub(r'/', ' ', text)\n",
        "    text = re.sub(r'[^a-z0-9\\s]', ' ', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    PRE_ABBR = [\n",
        "        (re.compile(r\"\\bcd\\.?\\s*no\\b\", flags=re.IGNORECASE), \"cadde no\"),\n",
        "        (re.compile(r\"\\bcd\\.?\\b\", flags=re.IGNORECASE), \"cadde\"),\n",
        "        (re.compile(r\"\\bsk\\.?\\s*no\\b\", flags=re.IGNORECASE), \"sokak no\"),\n",
        "        (re.compile(r\"\\bsk\\.?\\b\", flags=re.IGNORECASE), \"sokak\"),\n",
        "        (re.compile(r\"\\bm[hl]?\\.?\\b\", flags=re.IGNORECASE), \"mah\"),\n",
        "        (re.compile(r\"\\bb(\\d+)\\b\", flags=re.IGNORECASE), r\"blok \\1\"),\n",
        "        (re.compile(r\"\\bd(\\d+)\\b\", flags=re.IGNORECASE), r\"daire \\1\"),\n",
        "    ]\n",
        "\n",
        "    for pat, rep in PRE_ABBR:\n",
        "        text = pat.sub(rep, text)\n",
        "    return text\n",
        "\n",
        "# -------- Load CSVs --------\n",
        "train_path = os.path.join(data_path, \"train.csv\")\n",
        "test_path  = os.path.join(data_path, \"test.csv\")\n",
        "\n",
        "train_df = pd.read_csv(train_path)#.head(50)   # first 50 rows\n",
        "test_df  = pd.read_csv(test_path)#.head(50)\n",
        "\n",
        "# ⚠️ adjust this if your address column has another name\n",
        "ADDRESS_COL = \"address\"\n",
        "\n",
        "train_addrs = train_df[ADDRESS_COL].dropna().astype(str).tolist()\n",
        "test_addrs  = test_df[ADDRESS_COL].dropna().astype(str).tolist()\n",
        "\n",
        "# -------- Apply manual pre-normalization --------\n",
        "all_addrs = [pre_normalize_manual(addr) for addr in (train_addrs + test_addrs)]\n",
        "\n",
        "\n",
        "\n",
        "# -------- Save to file for Java --------\n",
        "clean_addresses = []\n",
        "with open(\"to_normalize.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    for addr in all_addrs:\n",
        "        if addr and addr.strip():   # skip empty or whitespace-only\n",
        "            f.write(addr.strip() + \"\\n\")\n",
        "            clean_addresses.append(addr.strip())\n",
        "\n",
        "print(f\"Saved {len(clean_addresses)} clean addresses to to_normalize.txt\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YF3lU-Yp2AcF",
        "outputId": "5a89a37b-fcb8-4ec8-9ed2-47623669bc6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved 1065475 clean addresses to to_normalize.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile NormalizeFullSentence.java\n",
        "import zemberek.morphology.TurkishMorphology;\n",
        "import zemberek.normalization.TurkishSentenceNormalizer;\n",
        "import java.nio.file.*;\n",
        "import java.io.*;\n",
        "import java.util.*;\n",
        "\n",
        "public class NormalizeFullSentence {\n",
        "    public static void main(String[] args) throws Exception {\n",
        "\n",
        "        // Create default Turkish morphology\n",
        "        TurkishMorphology morphology = TurkishMorphology.createWithDefaults();\n",
        "\n",
        "        // Set paths to normalization resources\n",
        "        Path zemberekDataRoot = Paths.get(\"/content/\"); // adjust to your root folder\n",
        "        Path lookupRoot = zemberekDataRoot.resolve(\"normalization\");\n",
        "        Path lmPath = zemberekDataRoot.resolve(\"lm.2gram.slm\");\n",
        "\n",
        "        // Initialize the TurkishSentenceNormalizer\n",
        "        TurkishSentenceNormalizer normalizer =\n",
        "            new TurkishSentenceNormalizer(morphology, lookupRoot, lmPath);\n",
        "\n",
        "        // Read lines from file\n",
        "        List<String> inputs = Files.readAllLines(Paths.get(\"to_normalize.txt\"));\n",
        "\n",
        "        // Normalize and print\n",
        "        for (String sentence : inputs) {\n",
        "            try {\n",
        "                String normalized = normalizer.normalize(sentence);\n",
        "                System.out.println(normalized);\n",
        "            } catch (Exception e) {\n",
        "                System.out.println(sentence); // fallback: print original\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgsQn_yJMub_",
        "outputId": "9b52aff7-af88-4327-932c-fafc421af5e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing NormalizeFullSentence.java\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!javac -cp zemberek-full.jar NormalizeFullSentence.java\n"
      ],
      "metadata": {
        "id": "nUwxEbWuM5Bp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!java -cp .:zemberek-full.jar NormalizeFullSentence > zemberek_output.txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NY03j2OpCrKM",
        "outputId": "b7ddef89-4292-4034-e16f-ccb3054e1cc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I|08:43:21.949|Root lexicon created in 2179 ms.                                                                    | DictionarySerializer#getDictionaryItems\n",
            "I|08:43:21.953|Dictionary generated in 2458 ms                                                                     | RootLexicon#defaultBinaryLexicon\n",
            "I|08:43:23.551|Initialized in 4538 ms.                                                                             | TurkishMorphology#createWithDefaults\n",
            "I|08:43:25.402|Language model = Order : 2\n",
            "1 Grams: Count= 300003\n",
            "2 Grams: Count= 19499916  Fingerprint Bits= 24  Probabilty Bits= 8  Back-off bits= 0\n",
            "Log Base              : 2.72\n",
            "Unigram Weight        : 1.00\n",
            "Using Stupid Back-off?: No\n",
            "Unknown Back-off N-gram penalty: 0.00\n",
            "| TurkishSentenceNormalizer#<init>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wc -l zemberek_output.txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5bASjAPCnI7",
        "outputId": "07c18df7-8db0-458c-db7d-6af19f4a01b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1065475 zemberek_output.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !java -cp .:zemberek-full.jar NormalizeFullSentence > zemberek_output.txt\n",
        "\n",
        "!java -jar zemberek-full.jar train_addresses.txt > zemberek_train_output.txt\n",
        "!java -jar zemberek-full.jar test_addresses.txt > zemberek_test_output.txt\n"
      ],
      "metadata": {
        "id": "pO1pNrh1M_4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wc -l train_addresses.txt\n",
        "!wc -l zemberek_train_output.txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Ry7fyrr9Zdk",
        "outputId": "8c3d86e7-9a85-4b55-b802-98ad298c9877"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wc: train_addresses.txt: No such file or directory\n",
            "73 zemberek_train_output.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# import pandas as pd\n",
        "# from rapidfuzz import process\n",
        "\n",
        "# # --- Load your official gazetteer ---\n",
        "# mahalle_excel_path = os.path.join(edudum_mahalle_listesi_path, \"Mahalle_Listesi.xls\")\n",
        "# gazetteer_df = pd.read_excel(mahalle_excel_path)\n",
        "\n",
        "# # Rename properly to lowercase/underscore versions\n",
        "# gazetteer_df = gazetteer_df.rename(columns={\n",
        "#     \"SIRA\": \"sira\",\n",
        "#     \"MAHALLE ADI \": \"mahalle_adi\",\n",
        "#     \"MAHALLENİN BAĞLILIK BİLGİSİ\": \"baglilik_bilgisi\"\n",
        "# })\n",
        "\n",
        "# # Split province, district, central_unit\n",
        "# gazetteer_df[['province', 'district', 'central_unit']] = (\n",
        "#     gazetteer_df['baglilik_bilgisi'].str.split(' -> ', expand=True, n=2)\n",
        "# )\n",
        "\n",
        "# # Drop rows with missing essentials\n",
        "# gazetteer_df = gazetteer_df.dropna(subset=['province', 'district', 'mahalle_adi'])\n",
        "\n",
        "# # Build gazetteer lists\n",
        "# provinces = gazetteer_df['province'].dropna().unique().tolist()\n",
        "# districts = gazetteer_df['district'].dropna().unique().tolist()\n",
        "# mahalleler = gazetteer_df['mahalle_adi'].dropna().unique().tolist()\n",
        "\n",
        "# gazetteer = {\n",
        "#     'provinces': provinces,\n",
        "#     'districts': districts,\n",
        "#     'mahalleler': mahalleler,\n",
        "#     'province_to_districts': gazetteer_df.groupby('province')['district'].apply(set).to_dict()\n",
        "# }\n",
        "\n",
        "# # --- Read Zemberek outputs ---\n",
        "# with open(\"zemberek_output.txt\", \"r\") as f:\n",
        "#     normalized_addresses = [line.strip() for line in f if line.strip()]\n",
        "\n",
        "# # --- Fuzzy matching helper ---\n",
        "# def match_with_gazetteer(text, gazetteer):\n",
        "#     province = process.extractOne(text, gazetteer['provinces'], score_cutoff=80)\n",
        "#     district = process.extractOne(text, gazetteer['districts'], score_cutoff=80)\n",
        "#     mahalle = process.extractOne(text, gazetteer['mahalleler'], score_cutoff=80)\n",
        "#     return {\n",
        "#         \"province\": province[0] if province else None,\n",
        "#         \"district\": district[0] if district else None,\n",
        "#         \"mahalle\": mahalle[0] if mahalle else None\n",
        "#     }\n",
        "\n",
        "# # --- Process all addresses ---\n",
        "# results = []\n",
        "# for addr in normalized_addresses:\n",
        "#     match = match_with_gazetteer(addr, gazetteer)\n",
        "#     results.append({\n",
        "#         \"normalized_zemberek\": addr,\n",
        "#         \"matched_province\": match['province'],\n",
        "#         \"matched_district\": match['district'],\n",
        "#         \"matched_mahalle\": match['mahalle']\n",
        "#     })\n",
        "\n",
        "# results_df = pd.DataFrame(results)\n",
        "# results_df.head(10)\n"
      ],
      "metadata": {
        "id": "_8w6sVOKV7oD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import os, re\n",
        "# import pandas as pd\n",
        "# from rapidfuzz import process, fuzz\n",
        "# from unidecode import unidecode\n",
        "\n",
        "# # ---------------------------\n",
        "# # Helpers\n",
        "# # ---------------------------\n",
        "# def norm(s: str) -> str:\n",
        "#     return unidecode(str(s)).lower().strip()\n",
        "\n",
        "# def has_word(a_norm: str, token_norm: str) -> bool:\n",
        "#     # kelime sınırlarıyla alt dize araması\n",
        "#     return re.search(rf'(?<!\\w){re.escape(token_norm)}(?!\\w)', a_norm) is not None\n",
        "\n",
        "# def extract_mahalle_phrase(addr_norm: str) -> str | None:\n",
        "#     # \"... <isim> mah.\" veya \"... <isim> mahallesi\"\n",
        "#     m = re.search(r'([a-z0-9çğıöşü\\-\\s]{2,60})\\s+m(?:ah(?:\\.|allesi)?)\\b', addr_norm)\n",
        "#     if not m:\n",
        "#         return None\n",
        "#     phrase = m.group(1).strip()\n",
        "#     toks = [t for t in phrase.split() if t and not t.isdigit()]\n",
        "#     if not toks:\n",
        "#         return None\n",
        "#     # Mahalle adı genelde sonda; son 1–3 token'ı odak al\n",
        "#     focus = \" \".join(toks[-3:])\n",
        "#     return focus\n",
        "\n",
        "# def best_match(query: str, candidates: list[str], cutoff=85, scorer=fuzz.token_set_ratio):\n",
        "#     if not candidates:\n",
        "#         return None, 0\n",
        "#     hit = process.extractOne(query, candidates, scorer=scorer, score_cutoff=cutoff)\n",
        "#     return (hit[0], hit[1]) if hit else (None, 0)\n",
        "\n",
        "# # ---------------------------\n",
        "# # Load Gazetteer\n",
        "# # ---------------------------\n",
        "# mahalle_excel_path = os.path.join(edudum_mahalle_listesi_path, \"Mahalle_Listesi.xls\")\n",
        "# raw = pd.read_excel(mahalle_excel_path)\n",
        "\n",
        "# # Kolon adlarını güvenli biçimde eşle\n",
        "# name_map = {}\n",
        "# for c in raw.columns:\n",
        "#     lc = unidecode(c).lower().strip()\n",
        "#     if lc.startswith(\"sira\"):\n",
        "#         name_map[c] = \"sira\"\n",
        "#     elif \"mahalle\" in lc and \"ad\" in lc:\n",
        "#         name_map[c] = \"mahalle_adi\"\n",
        "#     elif \"baglilik\" in lc:\n",
        "#         name_map[c] = \"baglilik_bilgisi\"\n",
        "\n",
        "# gazetteer_df = raw.rename(columns=name_map)[[\"sira\", \"mahalle_adi\", \"baglilik_bilgisi\"]].copy()\n",
        "# gazetteer_df[[\"province\", \"district\", \"central_unit\"]] = (\n",
        "#     gazetteer_df[\"baglilik_bilgisi\"].astype(str).str.split(\" -> \", expand=True, n=2)\n",
        "# )\n",
        "# gazetteer_df = gazetteer_df.dropna(subset=[\"province\", \"district\", \"mahalle_adi\"])\n",
        "\n",
        "# # Normalize columns for matching\n",
        "# gazetteer_df[\"prov_norm\"] = gazetteer_df[\"province\"].map(norm)\n",
        "# gazetteer_df[\"dist_norm\"] = gazetteer_df[\"district\"].map(norm)\n",
        "# gazetteer_df[\"mah_norm\"]  = gazetteer_df[\"mahalle_adi\"].map(norm)\n",
        "\n",
        "# # Unique + mapping (norm -> orijinal)\n",
        "# prov_map = gazetteer_df.drop_duplicates(\"prov_norm\").set_index(\"prov_norm\")[\"province\"].to_dict()\n",
        "# dist_map = gazetteer_df.drop_duplicates(\"dist_norm\").set_index(\"dist_norm\")[\"district\"].to_dict()\n",
        "# mah_map  = gazetteer_df.drop_duplicates(\"mah_norm\").set_index(\"mah_norm\")[\"mahalle_adi\"].to_dict()\n",
        "\n",
        "# prov_list_norm = list(prov_map.keys())\n",
        "# dist_list_norm = list(dist_map.keys())\n",
        "# mah_list_norm  = list(mah_map.keys())\n",
        "\n",
        "# # İl -> ilçeler (normalize)\n",
        "# dist_by_prov_norm = (\n",
        "#     gazetteer_df.groupby(\"prov_norm\")[\"dist_norm\"]\n",
        "#     .apply(lambda s: set(s.dropna().unique().tolist()))\n",
        "#     .to_dict()\n",
        "# )\n",
        "\n",
        "# # ---------------------------\n",
        "# # Read Zemberek outputs\n",
        "# # ---------------------------\n",
        "# with open(\"zemberek_output.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "#     normalized_addresses = [line.strip() for line in f if line.strip()]\n",
        "\n",
        "# # ---------------------------\n",
        "# # Matching\n",
        "# # ---------------------------\n",
        "# def match_with_gazetteer(addr_text: str):\n",
        "#     a_norm = norm(addr_text)\n",
        "#     # parçalar: / , -\n",
        "#     parts = re.split(r\"[,/|\\-]\", a_norm)\n",
        "#     parts = [\" \".join([t for t in p.split() if t]) for p in parts]\n",
        "\n",
        "#     # ---- Province (direct hit first)\n",
        "#     prov_hits = []\n",
        "#     for p_norm in prov_list_norm:\n",
        "#         if any(has_word(part, p_norm) for part in parts):\n",
        "#             prov_hits.append(p_norm)\n",
        "#     if prov_hits:\n",
        "#         prov_norm = max(prov_hits, key=len)  # en uzun adı seç (daha ayırt edici)\n",
        "#     else:\n",
        "#         prov_norm, _ = best_match(a_norm, prov_list_norm, cutoff=87)\n",
        "\n",
        "#     # ---- District (restrict by province if found)\n",
        "#     if prov_norm and prov_norm in dist_by_prov_norm:\n",
        "#         dist_candidates = list(dist_by_prov_norm[prov_norm])\n",
        "#     else:\n",
        "#         dist_candidates = dist_list_norm\n",
        "#     dist_norm, _ = best_match(a_norm, dist_candidates, cutoff=86)\n",
        "\n",
        "#     # ---- Mahalle (context-aware around 'mah')\n",
        "#     mah_phrase = extract_mahalle_phrase(a_norm)\n",
        "#     if mah_phrase:\n",
        "#         mah_norm, _ = best_match(mah_phrase, mah_list_norm, cutoff=85)\n",
        "#     else:\n",
        "#         # bağlam yoksa daha sıkı eşik kullan\n",
        "#         mah_norm, _ = best_match(a_norm, mah_list_norm, cutoff=92)\n",
        "\n",
        "#     return {\n",
        "#         \"province\": prov_map.get(prov_norm),\n",
        "#         \"district\": dist_map.get(dist_norm),\n",
        "#         \"mahalle\":  mah_map.get(mah_norm),\n",
        "#     }\n",
        "\n",
        "# # ---------------------------\n",
        "# # Run\n",
        "# # ---------------------------\n",
        "# rows = []\n",
        "# for addr in normalized_addresses:\n",
        "#     m = match_with_gazetteer(addr)\n",
        "#     rows.append({\n",
        "#         \"normalized_zemberek\": addr,\n",
        "#         \"matched_province\": m[\"province\"],\n",
        "#         \"matched_district\": m[\"district\"],\n",
        "#         \"matched_mahalle\":  m[\"mahalle\"],\n",
        "#     })\n",
        "\n",
        "# results_df = pd.DataFrame(rows)\n",
        "# print(results_df.head(10))\n"
      ],
      "metadata": {
        "id": "5aK6jjon4zau"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_df.iloc[7][\"normalized_zemberek\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "eiiH6tuRZ_mp",
        "outputId": "6d9145bf-7190-4627-b356-b4fa8b3b3a65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'bahçelivlr mh 7. cad 23. şano : 12a site3blokb daire : 21 Çankaya'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Address normalization + segmentation + gazetteer matching\n",
        "# (Zemberek çıktısına ek kural seti)\n",
        "# ============================================\n",
        "\n",
        "import os, re\n",
        "import pandas as pd\n",
        "from unidecode import unidecode\n",
        "from rapidfuzz import process, fuzz\n",
        "\n",
        "# ---------------------------\n",
        "# 0) PATHS\n",
        "# ---------------------------\n",
        "# Zemberek çıktısı (satır başına bir normalize edilmiş adres)\n",
        "ZEMBEREK_OUTPUT = \"zemberek_output.txt\"\n",
        "\n",
        "# Mahalle_Listesi.xls'in olduğu klasör\n",
        "# (örn: edudum_mahalle_listesi_path = \"/content/.cache/..../versions/1\")\n",
        "mahalle_excel_path = os.path.join(edudum_mahalle_listesi_path, \"Mahalle_Listesi.xls\")\n",
        "\n",
        "# ---------------------------\n",
        "# 1) NORMALIZATION HELPERS\n",
        "# ---------------------------\n",
        "\n",
        "# Küçük harf + TR diakritiklerini KORU (sınırlı ASCII'ye çevirmiyoruz).\n",
        "def lower_strip(s: str) -> str:\n",
        "    return s.casefold().strip()\n",
        "\n",
        "# Hız için regex'leri derleyelim\n",
        "SPACES = re.compile(r\"\\s+\")\n",
        "PUNCT_SPACING = re.compile(r\"\\s*([:/\\-.,])\\s*\")\n",
        "DOT_NUMBER = re.compile(r\"\\b(\\d+)\\.(?=\\s*(cad|cadd|cadde|sk|sok|sokak)\\b)\")  # 7.cad -> 7. cad\n",
        "SLASH_PAIR = re.compile(r\"\\b(\\d+)\\s*/\\s*([0-9a-zA-Z]+)\\b\")                     # 10/4 -> no 10 daire 4 (aşağıda bağlama göre)\n",
        "\n",
        "# Etiket (mah, cad, sk vs.) genişletmeleri — varyasyonları tek tipe çekiyoruz.\n",
        "ABBR_PATTERNS = [\n",
        "    (re.compile(r\"\\b(mahalle|mah\\.?|mhl|mh)\\b\"),          \"mahallesi\"),\n",
        "    (re.compile(r\"\\b(cadde|cadd|cad\\.?|cd)\\b\"),           \"cadde\"),\n",
        "    (re.compile(r\"\\b(bulvar[ıi]?|bulv|blv)\\b\"),           \"bulvar\"),\n",
        "    (re.compile(r\"\\b(sokak|sok\\.?|skk|sk)\\b\"),            \"sokak\"),\n",
        "    (re.compile(r\"\\b(apartman[ıi]?|apartmani|apt|ap)\\b\"), \"apartman\"),\n",
        "    (re.compile(r\"\\b(site(si)?)\\b\"),                      \"sitesi\"),\n",
        "    (re.compile(r\"\\b(no|num|numara)\\b\"),                  \"no\"),\n",
        "    (re.compile(r\"\\b(daire|dai)\\b\"),                      \"daire\"),\n",
        "    (re.compile(r\"\\b(kat)\\b\"),                            \"kat\"),\n",
        "    (re.compile(r\"\\b(blok|blk|bl)\\b\"),                    \"blok\"),\n",
        "]\n",
        "\n",
        "# “b1” -> “blok 1”, “d5” -> “daire 5” gibi kompakt yazımlar.\n",
        "COMPACT_NUM = [\n",
        "    (re.compile(r\"(?<!\\w)b\\s*(\\d+)\\b\"), \"blok \\\\1\"),\n",
        "    # Daire: sadece sayı takip ediyorsa (örn: d:5, d5). \"d blok\"u bozmayalım diye iki kural:\n",
        "    (re.compile(r\"\\bd\\s*[:\\-]?\\s*(\\d+)\\b(?!\\s*blok)\"), \"daire \\\\1\"),\n",
        "]\n",
        "\n",
        "# “no 10/4” ya da “10/4” -> “no 10 daire 4”\n",
        "def fix_no_slash_pairs(text: str) -> str:\n",
        "    def _repl(m):\n",
        "        left, right = m.group(1), m.group(2)\n",
        "        # Eğer hemen öncesinde “no” geçiyorsa sadece “daire” ekle\n",
        "        before = text[:m.start()]\n",
        "        if re.search(r\"no\\s*$\", before):\n",
        "            return f\"{left} daire {right}\"\n",
        "        return f\"no {left} daire {right}\"\n",
        "    return SLASH_PAIR.sub(_repl, text)\n",
        "\n",
        "# “no:12”, “kat:3”, “d:5” gibi yazımları standardize et -> “no 12”, “kat 3”, “daire 5”\n",
        "LABEL_COLON = [\n",
        "    (re.compile(r\"\\bno\\s*[:=]\\s*\"), \"no \"),\n",
        "    (re.compile(r\"\\bkat\\s*[:=]\\s*\"), \"kat \"),\n",
        "    (re.compile(r\"\\bdaire\\s*[:=]\\s*\"), \"daire \"),\n",
        "    (re.compile(r\"\\bblok\\s*[:=]\\s*\"), \"blok \"),\n",
        "]\n",
        "\n",
        "# “kat3” -> “kat 3”, “daire21” -> “daire 21”, “blokb” -> “blok b”\n",
        "ATTACH_FIX = [\n",
        "    (re.compile(r\"\\b(kat)(\\d+)\\b\"), r\"\\1 \\2\"),\n",
        "    (re.compile(r\"\\b(daire)(\\d+)\\b\"), r\"\\1 \\2\"),\n",
        "    (re.compile(r\"\\b(blok)([a-z0-9]+)\\b\"), r\"\\1 \\2\"),\n",
        "]\n",
        "\n",
        "# Bazı gürültüleri temizle\n",
        "NOISE = [\n",
        "    (re.compile(r\"\\btr\\b|\\bturkiye\\b|\\bturkey\\b\"), \" \"),\n",
        "    (re.compile(r\"(?<=\\d)[,](?=\\d)\"), \".\"),  # 1,234 -> 1.234 (nokta veya boşluk isteniyorsa değiştir)\n",
        "]\n",
        "\n",
        "def normalize_manual(text: str) -> str:\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "    t = lower_strip(text)\n",
        "\n",
        "    # Noktalama çevresi boşluklar (\"/\", \":\", \".\", \",\", \"-\")\n",
        "    t = PUNCT_SPACING.sub(r\" \\1 \", t)\n",
        "    # 7.cad -> 7. cad\n",
        "    t = DOT_NUMBER.sub(r\"\\1. \", t)\n",
        "\n",
        "    # Kısaltmaları genişlet\n",
        "    for pat, rep in ABBR_PATTERNS:\n",
        "        t = pat.sub(rep, t)\n",
        "\n",
        "    # Kompakt kısaltmalar\n",
        "    for pat, rep in COMPACT_NUM:\n",
        "        t = pat.sub(rep, t)\n",
        "\n",
        "    # no:12 -> no 12 vb.\n",
        "    for pat, rep in LABEL_COLON:\n",
        "        t = pat.sub(rep, t)\n",
        "\n",
        "    # 10/4 -> no 10 daire 4 (bağlama duyarlı)\n",
        "    t = fix_no_slash_pairs(t)\n",
        "\n",
        "    # kat3 -> kat 3, daire21 -> daire 21, blokb -> blok b\n",
        "    for pat, rep in ATTACH_FIX:\n",
        "        t = pat.sub(rep, t)\n",
        "\n",
        "    # Gürültüler\n",
        "    for pat, rep in NOISE:\n",
        "        t = pat.sub(rep, t)\n",
        "\n",
        "    # Çoklu boşluk\n",
        "    t = SPACES.sub(\" \", t).strip()\n",
        "    return t\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# 2) SEGMENTATION (alan çıkarımı)\n",
        "# ---------------------------\n",
        "# Daha istikrarlı sonuç için “etiket + değer” yakala.\n",
        "R_MAH = re.compile(r\"(?P<name>[a-z0-9\\-\\s]{2,60})\\s+mahallesi\\b\")\n",
        "R_CAD = re.compile(r\"(?P<name>[0-9a-z\\-\\.\\s]{1,60})\\s+cadde\\b\")\n",
        "R_SOK = re.compile(r\"(?P<name>[0-9a-z\\-\\.\\s]{1,60})\\s+sokak\\b\")\n",
        "R_BUL = re.compile(r\"(?P<name>[0-9a-z\\-\\.\\s]{1,60})\\s+bulvar\\b\")\n",
        "R_SITE = re.compile(r\"\\b(?P<name>[0-9a-z\\-\\.\\s]{2,80})\\s+sitesi\\b\")\n",
        "R_NO = re.compile(r\"\\bno\\s+(?P<val>[0-9a-z]+)\\b\")\n",
        "R_KAT = re.compile(r\"\\bkat\\s+(?P<val>[0-9a-z\\-]+)\\b\")\n",
        "R_DAI = re.compile(r\"\\bdaire\\s+(?P<val>[0-9a-z\\-]+)\\b\")\n",
        "R_BLOK = re.compile(r\"\\bblok\\s+(?P<val>[0-9a-z\\-]+)\\b\")\n",
        "\n",
        "def _tail_tokens(s, k=3):\n",
        "    toks = [tok for tok in s.split() if tok and not tok.isdigit()]\n",
        "    return \" \".join(toks[-k:]) if toks else None\n",
        "\n",
        "def segment_address(addr: str) -> dict:\n",
        "    a = addr\n",
        "\n",
        "    def pick(m, field, k=3):\n",
        "        if not m:\n",
        "            return None\n",
        "        name = m.group(\"name\").strip()\n",
        "        return _tail_tokens(name, k=k)\n",
        "\n",
        "    seg = {\n",
        "        \"mah\": pick(R_MAH.search(a), \"mah\"),\n",
        "        \"cadde\": pick(R_CAD.search(a), \"cadde\"),\n",
        "        \"sokak\": pick(R_SOK.search(a), \"sokak\"),\n",
        "        \"bulvar\": pick(R_BUL.search(a), \"bulvar\"),\n",
        "        \"site\": pick(R_SITE.search(a), \"site\", k=4),\n",
        "        \"no\": (R_NO.search(a).group(\"val\") if R_NO.search(a) else None),\n",
        "        \"kat\": (R_KAT.search(a).group(\"val\") if R_KAT.search(a) else None),\n",
        "        \"daire\": (R_DAI.search(a).group(\"val\") if R_DAI.search(a) else None),\n",
        "        \"blok\": (R_BLOK.search(a).group(\"val\") if R_BLOK.search(a) else None),\n",
        "    }\n",
        "    return seg\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# 3) GAZETTEER YÜKLE + NORMALİZE\n",
        "# ---------------------------\n",
        "raw = pd.read_excel(mahalle_excel_path)\n",
        "\n",
        "# Kolon isimleri değişebilir; güvenli yeniden adlandırma:\n",
        "name_map = {}\n",
        "for c in raw.columns:\n",
        "    lc = unidecode(str(c)).lower().strip()\n",
        "    if lc.startswith(\"sira\"):\n",
        "        name_map[c] = \"sira\"\n",
        "    elif \"mahalle\" in lc and \"ad\" in lc:\n",
        "        name_map[c] = \"mahalle_adi\"\n",
        "    elif \"baglilik\" in lc:\n",
        "        name_map[c] = \"baglilik_bilgisi\"\n",
        "\n",
        "gazetteer_df = raw.rename(columns=name_map)[[\"sira\", \"mahalle_adi\", \"baglilik_bilgisi\"]].copy()\n",
        "gazetteer_df[[\"province\", \"district\", \"central_unit\"]] = (\n",
        "    gazetteer_df[\"baglilik_bilgisi\"].astype(str).str.split(\" -> \", expand=True, n=2)\n",
        ")\n",
        "gazetteer_df = gazetteer_df.dropna(subset=[\"province\", \"district\", \"mahalle_adi\"])\n",
        "\n",
        "# Normalizasyon (eşleşme için)\n",
        "gazetteer_df[\"prov_norm\"] = gazetteer_df[\"province\"].map(lambda x: unidecode(str(x)).lower().strip())\n",
        "gazetteer_df[\"dist_norm\"] = gazetteer_df[\"district\"].map(lambda x: unidecode(str(x)).lower().strip())\n",
        "gazetteer_df[\"mah_norm\"]  = gazetteer_df[\"mahalle_adi\"].map(lambda x: unidecode(str(x)).lower().strip())\n",
        "\n",
        "prov_map = gazetteer_df.drop_duplicates(\"prov_norm\").set_index(\"prov_norm\")[\"province\"].to_dict()\n",
        "dist_map = gazetteer_df.drop_duplicates(\"dist_norm\").set_index(\"dist_norm\")[\"district\"].to_dict()\n",
        "mah_map  = gazetteer_df.drop_duplicates(\"mah_norm\").set_index(\"mah_norm\")[\"mahalle_adi\"].to_dict()\n",
        "\n",
        "prov_list_norm = list(prov_map.keys())\n",
        "dist_list_norm = list(dist_map.keys())\n",
        "mah_list_norm  = list(mah_map.keys())\n",
        "\n",
        "# il -> ilçe kısıtı\n",
        "dist_by_prov_norm = (\n",
        "    gazetteer_df.groupby(\"prov_norm\")[\"dist_norm\"]\n",
        "    .apply(lambda s: set(s.dropna().unique().tolist()))\n",
        "    .to_dict()\n",
        ")\n",
        "\n",
        "def best_match(query: str, candidates: list[str], cutoff=86, scorer=fuzz.token_set_ratio):\n",
        "    if not candidates:\n",
        "        return None, 0\n",
        "    hit = process.extractOne(query, candidates, scorer=scorer, score_cutoff=cutoff)\n",
        "    return (hit[0], hit[1]) if hit else (None, 0)\n",
        "\n",
        "# mahalle bağlamsal: “... X mahallesi” içinde geçen kısım\n",
        "def extract_mah_focus(addr_norm: str) -> str | None:\n",
        "    m = re.search(r\"([a-z0-9\\-\\s]{2,60})\\s+mahallesi\\b\", addr_norm)\n",
        "    if not m:\n",
        "        return None\n",
        "    return _tail_tokens(m.group(1), k=3)\n",
        "\n",
        "def match_with_gazetteer(addr_text_norm: str, seg: dict):\n",
        "    # Eşleşmeyi ASCII normal üzerinde yapıyoruz\n",
        "    a_norm = unidecode(addr_text_norm).lower().strip()\n",
        "    parts = re.split(r\"[,/|\\-]\", a_norm)\n",
        "    parts = [\" \".join([t for t in p.split() if t]) for p in parts]\n",
        "\n",
        "    # İl: önce doğrudan parçalarda, yoksa fuzzy\n",
        "    prov_hits = [p for p in prov_list_norm if any(re.search(rf\"(?<!\\w){re.escape(p)}(?!\\w)\", part) for part in parts)]\n",
        "    if prov_hits:\n",
        "        prov_norm = max(prov_hits, key=len)\n",
        "    else:\n",
        "        prov_norm, _ = best_match(a_norm, prov_list_norm, cutoff=87)\n",
        "\n",
        "    # İlçe: il'e bağlı havuzda dene, yoksa genelde\n",
        "    dist_candidates = list(dist_by_prov_norm.get(prov_norm, [])) or dist_list_norm\n",
        "    dist_norm, _ = best_match(a_norm, dist_candidates, cutoff=86)\n",
        "\n",
        "    # Mahalle: önce regex bağlamı, yoksa tüm havuz\n",
        "    focus = extract_mah_focus(a_norm) or seg.get(\"mah\")\n",
        "    if focus:\n",
        "        mah_norm, _ = best_match(focus, mah_list_norm, cutoff=85)\n",
        "    else:\n",
        "        mah_norm, _ = best_match(a_norm, mah_list_norm, cutoff=92)\n",
        "\n",
        "    return {\n",
        "        \"province\": prov_map.get(prov_norm),\n",
        "        \"district\": dist_map.get(dist_norm),\n",
        "        \"mahalle_official\": mah_map.get(mah_norm),\n",
        "    }\n",
        "\n",
        "# ---------------------------\n",
        "# 4) PIPELINE: Zemberek -> Regex Normalization -> Segmentation -> Gazetteer\n",
        "# ---------------------------\n",
        "with open(ZEMBEREK_OUTPUT, \"r\", encoding=\"utf-8\") as f:\n",
        "    z_out = [line.strip() for line in f if line.strip()]\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "rows = []\n",
        "for addr in tqdm(z_out, desc=\"Processing addresses\"):\n",
        "    norm_addr = normalize_manual(addr)\n",
        "    seg = segment_address(norm_addr)\n",
        "    g = match_with_gazetteer(norm_addr, seg)\n",
        "    rows.append({\n",
        "        \"zemberek_out\": addr,\n",
        "        \"norm_rule_based\": norm_addr,\n",
        "        \"seg_mah\": seg[\"mah\"],\n",
        "        \"seg_cadde\": seg[\"cadde\"],\n",
        "        \"seg_sokak\": seg[\"sokak\"],\n",
        "        \"seg_bulvar\": seg[\"bulvar\"],\n",
        "        \"seg_site\": seg[\"site\"],\n",
        "        \"seg_blok\": seg[\"blok\"],\n",
        "        \"seg_no\": seg[\"no\"],\n",
        "        \"seg_kat\": seg[\"kat\"],\n",
        "        \"seg_daire\": seg[\"daire\"],\n",
        "        \"match_province\": g[\"province\"],\n",
        "        \"match_district\": g[\"district\"],\n",
        "        \"match_mahalle_official\": g[\"mahalle_official\"],\n",
        "    })\n",
        "\n",
        "results_df = pd.DataFrame(rows)\n",
        "\n",
        "# # İsteğe bağlı: kanonik adres üretme (alanları sıralı bir formata toplama)\n",
        "# def canonicalize(row):\n",
        "#     chunks = []\n",
        "#     if row.get(\"seg_mah\"):    chunks += [f\"{row['seg_mah']} mahallesi\"]\n",
        "#     if row.get(\"seg_cadde\"):  chunks += [f\"{row['seg_cadde']} cadde\"]\n",
        "#     if row.get(\"seg_sokak\"):  chunks += [f\"{row['seg_sokak']} sokak\"]\n",
        "#     if row.get(\"seg_bulvar\"): chunks += [f\"{row['seg_bulvar']} bulvar\"]\n",
        "#     if row.get(\"seg_site\"):   chunks += [f\"{row['seg_site']} sitesi\"]\n",
        "#     if row.get(\"seg_blok\"):   chunks += [f\"blok {row['seg_blok']}\"]\n",
        "#     if row.get(\"seg_no\"):     chunks += [f\"no {row['seg_no']}\"]\n",
        "#     if row.get(\"seg_kat\"):    chunks += [f\"kat {row['seg_kat']}\"]\n",
        "#     if row.get(\"seg_daire\"):  chunks += [f\"daire {row['seg_daire']}\"]\n",
        "#     # Sonuna idari birimler\n",
        "#     tail = [row.get(\"match_district\"), row.get(\"match_province\")]\n",
        "#     tail = [t for t in tail if isinstance(t, str) and t]\n",
        "#     if tail:\n",
        "#         chunks.append(\" / \".join(tail))\n",
        "#     return \" \".join(chunks).strip()\n",
        "\n",
        "# results_df[\"canonical_address\"] = results_df.apply(canonicalize, axis=1)\n",
        "\n",
        "print(results_df.head(10))\n"
      ],
      "metadata": {
        "id": "QNOQk1NjjIYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Address normalization + segmentation + gazetteer matching\n",
        "# (Uses Zemberek output directly; optional manual normalization for comparison)\n",
        "# ============================================\n",
        "\n",
        "import os, re\n",
        "import pandas as pd\n",
        "from unidecode import unidecode\n",
        "from rapidfuzz import process, fuzz\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ---------------------------\n",
        "# 0) PATHS\n",
        "# ---------------------------\n",
        "ZEMBEREK_OUTPUT = \"zemberek_output.txt\"\n",
        "mahalle_excel_path = os.path.join(edudum_mahalle_listesi_path, \"Mahalle_Listesi.xls\")\n",
        "\n",
        "# ---------------------------\n",
        "# 1) SEGMENTATION HELPERS\n",
        "# ---------------------------\n",
        "R_MAH = re.compile(r\"(?P<name>[a-z0-9\\-\\s]{2,60})\\s+mahallesi\\b\")\n",
        "R_CAD = re.compile(r\"(?P<name>[0-9a-z\\-\\.\\s]{1,60})\\s+cadde\\b\")\n",
        "R_SOK = re.compile(r\"(?P<name>[0-9a-z\\-\\.\\s]{1,60})\\s+sokak\\b\")\n",
        "R_BUL = re.compile(r\"(?P<name>[0-9a-z\\-\\.\\s]{1,60})\\s+bulvar\\b\")\n",
        "R_SITE = re.compile(r\"\\b(?P<name>[0-9a-z\\-\\.\\s]{2,80})\\s+sitesi\\b\")\n",
        "R_NO = re.compile(r\"\\bno\\s+(?P<val>[0-9a-z]+)\\b\")\n",
        "R_KAT = re.compile(r\"\\bkat\\s+(?P<val>[0-9a-z\\-]+)\\b\")\n",
        "R_DAI = re.compile(r\"\\bdaire\\s+(?P<val>[0-9a-z\\-]+)\\b\")\n",
        "R_BLOK = re.compile(r\"\\bblok\\s+(?P<val>[0-9a-z\\-]+)\\b\")\n",
        "\n",
        "def _tail_tokens(s, k=3):\n",
        "    toks = [tok for tok in s.split() if tok and not tok.isdigit()]\n",
        "    return \" \".join(toks[-k:]) if toks else None\n",
        "\n",
        "def segment_address(addr: str) -> dict:\n",
        "    a = addr\n",
        "    def pick(m, k=3):\n",
        "        if not m: return None\n",
        "        return _tail_tokens(m.group(\"name\").strip(), k=k)\n",
        "\n",
        "    return {\n",
        "        \"mah\": pick(R_MAH.search(a)),\n",
        "        \"cadde\": pick(R_CAD.search(a)),\n",
        "        \"sokak\": pick(R_SOK.search(a)),\n",
        "        \"bulvar\": pick(R_BUL.search(a)),\n",
        "        \"site\": pick(R_SITE.search(a), k=4),\n",
        "        \"no\": (R_NO.search(a).group(\"val\") if R_NO.search(a) else None),\n",
        "        \"kat\": (R_KAT.search(a).group(\"val\") if R_KAT.search(a) else None),\n",
        "        \"daire\": (R_DAI.search(a).group(\"val\") if R_DAI.search(a) else None),\n",
        "        \"blok\": (R_BLOK.search(a).group(\"val\") if R_BLOK.search(a) else None),\n",
        "    }\n",
        "\n",
        "# ---------------------------\n",
        "# 2) GAZETTEER\n",
        "# ---------------------------\n",
        "raw = pd.read_excel(mahalle_excel_path)\n",
        "name_map = {}\n",
        "for c in raw.columns:\n",
        "    lc = unidecode(str(c)).lower().strip()\n",
        "    if lc.startswith(\"sira\"): name_map[c] = \"sira\"\n",
        "    elif \"mahalle\" in lc and \"ad\" in lc: name_map[c] = \"mahalle_adi\"\n",
        "    elif \"baglilik\" in lc: name_map[c] = \"baglilik_bilgisi\"\n",
        "\n",
        "gazetteer_df = raw.rename(columns=name_map)[[\"sira\", \"mahalle_adi\", \"baglilik_bilgisi\"]].copy()\n",
        "gazetteer_df[[\"province\", \"district\", \"central_unit\"]] = (\n",
        "    gazetteer_df[\"baglilik_bilgisi\"].astype(str).str.split(\" -> \", expand=True, n=2)\n",
        ")\n",
        "gazetteer_df = gazetteer_df.dropna(subset=[\"province\", \"district\", \"mahalle_adi\"])\n",
        "\n",
        "gazetteer_df[\"prov_norm\"] = gazetteer_df[\"province\"].map(lambda x: unidecode(str(x)).lower().strip())\n",
        "gazetteer_df[\"dist_norm\"] = gazetteer_df[\"district\"].map(lambda x: unidecode(str(x)).lower().strip())\n",
        "gazetteer_df[\"mah_norm\"]  = gazetteer_df[\"mahalle_adi\"].map(lambda x: unidecode(str(x)).lower().strip())\n",
        "\n",
        "prov_map = gazetteer_df.drop_duplicates(\"prov_norm\").set_index(\"prov_norm\")[\"province\"].to_dict()\n",
        "dist_map = gazetteer_df.drop_duplicates(\"dist_norm\").set_index(\"dist_norm\")[\"district\"].to_dict()\n",
        "mah_map  = gazetteer_df.drop_duplicates(\"mah_norm\").set_index(\"mah_norm\")[\"mahalle_adi\"].to_dict()\n",
        "\n",
        "prov_list_norm = list(prov_map.keys())\n",
        "dist_list_norm = list(dist_map.keys())\n",
        "mah_list_norm  = list(mah_map.keys())\n",
        "\n",
        "dist_by_prov_norm = (\n",
        "    gazetteer_df.groupby(\"prov_norm\")[\"dist_norm\"]\n",
        "    .apply(lambda s: set(s.dropna().unique().tolist()))\n",
        "    .to_dict()\n",
        ")\n",
        "\n",
        "def best_match(query: str, candidates: list[str], cutoff=86, scorer=fuzz.token_set_ratio):\n",
        "    if not candidates:\n",
        "        return None, 0\n",
        "    hit = process.extractOne(query, candidates, scorer=scorer, score_cutoff=cutoff)\n",
        "    return (hit[0], hit[1]) if hit else (None, 0)\n",
        "\n",
        "def extract_mah_focus(addr_norm: str) -> str | None:\n",
        "    m = re.search(r\"([a-z0-9\\-\\s]{2,60})\\s+mahallesi\\b\", addr_norm)\n",
        "    return _tail_tokens(m.group(1), k=3) if m else None\n",
        "\n",
        "def match_with_gazetteer(addr_text_norm: str, seg: dict):\n",
        "    a_norm = unidecode(addr_text_norm).lower().strip()\n",
        "    parts = re.split(r\"[,/|\\-]\", a_norm)\n",
        "    parts = [\" \".join([t for t in p.split() if t]) for p in parts]\n",
        "\n",
        "    prov_hits = [p for p in prov_list_norm if any(re.search(rf\"(?<!\\w){re.escape(p)}(?!\\w)\", part) for part in parts)]\n",
        "    if prov_hits:\n",
        "        prov_norm = max(prov_hits, key=len)\n",
        "    else:\n",
        "        prov_norm, _ = best_match(a_norm, prov_list_norm, cutoff=87)\n",
        "\n",
        "    dist_candidates = list(dist_by_prov_norm.get(prov_norm, [])) or dist_list_norm\n",
        "    dist_norm, _ = best_match(a_norm, dist_candidates, cutoff=86)\n",
        "\n",
        "    focus = extract_mah_focus(a_norm) or seg.get(\"mah\")\n",
        "    if focus:\n",
        "        mah_norm, _ = best_match(focus, mah_list_norm, cutoff=85)\n",
        "    else:\n",
        "        mah_norm, _ = best_match(a_norm, mah_list_norm, cutoff=92)\n",
        "\n",
        "    return {\n",
        "        \"province\": prov_map.get(prov_norm),\n",
        "        \"district\": dist_map.get(dist_norm),\n",
        "        \"mahalle_official\": mah_map.get(mah_norm),\n",
        "    }\n",
        "\n",
        "# ---------------------------\n",
        "# 3) PIPELINE: Zemberek → Segmentation → Gazetteer\n",
        "# ---------------------------\n",
        "with open(ZEMBEREK_OUTPUT, \"r\", encoding=\"utf-8\") as f:\n",
        "    z_out = [line.strip() for line in f if line.strip()]\n",
        "\n",
        "rows = []\n",
        "for addr in tqdm(z_out, desc=\"Processing addresses\"):\n",
        "    seg = segment_address(addr)           # directly on zemberek_out\n",
        "    g = match_with_gazetteer(addr, seg)\n",
        "    rows.append({\n",
        "        \"zemberek_out\": addr,\n",
        "        # \"norm_rule_based\": normalize_manual(addr),  # <– enable only if you want comparison\n",
        "        \"seg_mah\": seg[\"mah\"],\n",
        "        \"seg_cadde\": seg[\"cadde\"],\n",
        "        \"seg_sokak\": seg[\"sokak\"],\n",
        "        \"seg_bulvar\": seg[\"bulvar\"],\n",
        "        \"seg_site\": seg[\"site\"],\n",
        "        \"seg_blok\": seg[\"blok\"],\n",
        "        \"seg_no\": seg[\"no\"],\n",
        "        \"seg_kat\": seg[\"kat\"],\n",
        "        \"seg_daire\": seg[\"daire\"],\n",
        "        \"match_province\": g[\"province\"],\n",
        "        \"match_district\": g[\"district\"],\n",
        "        \"match_mahalle_official\": g[\"mahalle_official\"],\n",
        "    })\n",
        "\n",
        "results_df = pd.DataFrame(rows)\n",
        "print(results_df.head(10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9Ve4m1a2gmO",
        "outputId": "86ce379c-a442-4838-f27a-82a727df2e97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing addresses: 100%|██████████| 1065475/1065475 [1:38:58<00:00, 179.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                        zemberek_out      seg_mah seg_cadde  \\\n",
            "0  akarca mahallesi adnan menderes caddesi 864 so...       akarca      None   \n",
            "1  cumhuriyet mahallesi hükümet caddesi sivriler ...   cumhuriyet      None   \n",
            "2  ismet inönü mahallesi 2001 sokağı numara 2 çeş...         None      None   \n",
            "3  gazeteci hasan tahsin caddesi numara 10 3 gize...         None      None   \n",
            "4  bitez mahallesi adnan menderes caddesi gündönü...        bitez      None   \n",
            "5  Derebaşı mahallesi 6100 sokağı numara 10 kat 7...         None      None   \n",
            "6  dikili güzelselde sitesi müsellim altı numara ...         None      None   \n",
            "7  yeni sanayi mahallesi 515 sokağı numara 53 c3 ...  yeni sanayi      None   \n",
            "8  pazaryeri mahallesi 417 sokağı numara 6 4 feth...    pazaryeri      None   \n",
            "9  gümüşlük mahallesi 5215 sokağı daire blok dış ...         None      None   \n",
            "\n",
            "  seg_sokak seg_bulvar seg_site seg_blok seg_no seg_kat seg_daire  \\\n",
            "0      None       None     None     None   None       2         1   \n",
            "1      None       None     None     None   None    None      None   \n",
            "2      None       None     None     None   None    None      None   \n",
            "3      None       None     None     None   None    None      None   \n",
            "4      None       None     None     None   None    None      None   \n",
            "5      None       None     None     None   None       7        25   \n",
            "6      None       None     None     None   None    None      None   \n",
            "7      None       None     None     emek   None    None      None   \n",
            "8      None       None     None     None   None    None      None   \n",
            "9      None       None     None     None   None    None      blok   \n",
            "\n",
            "  match_province match_district match_mahalle_official  \n",
            "0           None       MENDERES                 AKARCA  \n",
            "1          MUĞLA        FETHİYE             CUMHURİYET  \n",
            "2           None          İNÖNÜ                  İNÖNÜ  \n",
            "3           None           None                   None  \n",
            "4           None       MENDERES                  BİTEZ  \n",
            "5           None           None               DEREBAŞI  \n",
            "6          İZMİR         DİKİLİ               MÜSELLİM  \n",
            "7           None           None                   YENİ  \n",
            "8          MUĞLA        FETHİYE              PAZARYERİ  \n",
            "9          MUĞLA         BODRUM               GÜMÜŞLÜK  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# 5) TRAIN / TEST sonuçlarını ayır\n",
        "# ============================================\n",
        "\n",
        "n_train = len(train_df)\n",
        "train_rows = results_df.iloc[:n_train].reset_index(drop=True)\n",
        "test_rows  = results_df.iloc[n_train:].reset_index(drop=True)\n",
        "\n",
        "# Train sonuçlarına label ekle\n",
        "train_df_results = pd.concat([train_df.reset_index(drop=True), train_rows], axis=1)\n",
        "test_df_results  = pd.concat([test_df.reset_index(drop=True),  test_rows], axis=1)\n",
        "\n",
        "print(\"Train results with labels:\")\n",
        "print(train_df_results.head(10))\n",
        "\n",
        "print(\"\\nTest results (no labels):\")\n",
        "print(test_df_results.head(10))\n"
      ],
      "metadata": {
        "id": "6wlP_Uw5q98c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_df.shape\n",
        "\n"
      ],
      "metadata": {
        "id": "dp1Y8dWntcNx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df_results.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXKy-7p77oo5",
        "outputId": "a5d4fe20-db32-4a5a-c6bb-7897aea5fd99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(848237, 16)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df_results.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XU3zuV2x70gQ",
        "outputId": "75a3b23e-6e16-4d30-b9cc-115341e9eee4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(217241, 16)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    }
  ]
}